{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGWWbseNoeFZ4Eppl7xTaH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6f2a05604734de1874b861d393542ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f86a85ce7a9042d6aaca009064444ecd",
              "IPY_MODEL_912a59f189e945b2a5bb8773633b8371",
              "IPY_MODEL_1e0643baa00641438656efaa3adbf268"
            ],
            "layout": "IPY_MODEL_96a8dffd38d24ecdaec794dfd9a48433"
          }
        },
        "f86a85ce7a9042d6aaca009064444ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e08fa3808cf4951a829cc6f38fc5002",
            "placeholder": "​",
            "style": "IPY_MODEL_25316da561594da8af0c3dbcca4d8b5b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "912a59f189e945b2a5bb8773633b8371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c92fbe58874d558124a3efa0ac184f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_888e93a91be54db1ac8026d01ee2da90",
            "value": 2
          }
        },
        "1e0643baa00641438656efaa3adbf268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c2b2896e244b84b070fc45e339c8aa",
            "placeholder": "​",
            "style": "IPY_MODEL_c5ad50e1877646059619ff3c01a9b146",
            "value": " 2/2 [01:06&lt;00:00, 30.49s/it]"
          }
        },
        "96a8dffd38d24ecdaec794dfd9a48433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e08fa3808cf4951a829cc6f38fc5002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25316da561594da8af0c3dbcca4d8b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29c92fbe58874d558124a3efa0ac184f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888e93a91be54db1ac8026d01ee2da90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53c2b2896e244b84b070fc45e339c8aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ad50e1877646059619ff3c01a9b146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acucenarodrigues1998/TutorialPyBR2023-GenAINotebooks/blob/main/Tutorial_PyBR_XX_Question_Answering_com_LLM_e_banco_de_vetores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Large Language Models (LLMs)**\n",
        "As redes Large Language Models, ou modelos de linguagem de grande escala, são um tipo de modelo de aprendizado de máquina que foram desenvolvidos para processar e gerar texto natural em grande quantidade. Eles são treinados em vastos conjuntos de dados textuais, geralmente incluindo uma ampla variedade de textos da internet, como artigos, livros, sites da web e muito mais. Esses modelos são projetados para entender e gerar texto de maneira muito semelhante à linguagem humana, tornando-os úteis em uma variedade de tarefas de processamento de linguagem natural, como tradução automática, resumo de texto, geração de texto, classificação de texto e muito mais.\n",
        "\n",
        "Aqui está uma explicação simplificada de como esses modelos funcionam:\n",
        "\n",
        "1. **Arquitetura**: Os modelos de linguagem de grande escala geralmente usam arquiteturas de redes neurais profundas, como transformers. Essas arquiteturas são projetadas para lidar com sequências de palavras em texto, capturando as relações entre as palavras e os contextos em que elas aparecem.\n",
        "\n",
        "2. **Treinamento**: Para treinar esses modelos, uma grande quantidade de texto é alimentada à rede neural. O treinamento envolve a previsão da próxima palavra em uma sequência de palavras, com base no contexto anterior. O modelo ajusta seus parâmetros internos (pesos) para minimizar a discrepância entre suas previsões e o texto real.\n",
        "\n",
        "3. **Representações de palavras**: Durante o treinamento, o modelo aprende representações vetoriais de palavras (word embeddings) que capturam o significado e as relações entre as palavras. Isso permite que o modelo compreenda o contexto e a semântica das palavras em um texto.\n",
        "\n",
        "4. **Geração de texto**: Após o treinamento, o modelo pode ser usado para gerar texto. Dada uma entrada inicial (por exemplo, uma frase ou palavra), o modelo prevê as palavras subsequentes com base em seu conhecimento do contexto e das relações entre as palavras. Ele gera texto que é coerente e gramaticalmente correto.\n",
        "\n",
        "5. **Transferência de conhecimento**: Além da geração de texto, esses modelos podem ser ajustados (fine-tuning) para tarefas específicas, como classificação de sentimentos, tradução automática ou qualquer outra tarefa de processamento de linguagem natural. Isso é possível porque o modelo pré-treinado já possui um conhecimento linguístico geral que pode ser útil em tarefas mais específicas.\n",
        "\n",
        "6. **Reforço com Feedback Humano (RLHF)**: Para melhorar ainda mais o desempenho em tarefas específicas, os modelos podem ser ajustados com RLHF, recebendo feedback humano que ajuda a refinar sua capacidade de interagir com os usuários e melhorar o desempenho em situações do mundo real.\n",
        "\n",
        "Redes Large Language Models, como o GPT-3 da OpenAI, têm sido usadas em diversas aplicações, desde assistentes virtuais até geração de texto automatizada e pesquisa em linguística computacional. Eles têm o potencial de melhorar significativamente a capacidade de máquinas para entender e gerar texto natural, embora também apresentem desafios relacionados à ética e ao viés, que precisam ser considerados ao utilizá-los. O RLHF é uma técnica valiosa que ajuda a ajustar esses modelos para tarefas específicas com base no feedback humano.\n",
        "\n",
        "## Aplicação prática\n",
        "\n",
        "Para esse tema utilizaremos o modelo LLaMa 2 e um banco de vetores, disponibilizado pela Meta e construiremos uma estrutura de perguntas e respostas utilizando como base de dados algum site da internet."
      ],
      "metadata": {
        "id": "J1JZXB-_R9sm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ptsg5B8B6xt"
      },
      "outputs": [],
      "source": [
        "!pip install -qU transformers accelerate einops langchain xformers bitsandbytes faiss-gpu sentence_transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda, bfloat16\n",
        "import transformers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "zEFYu8v1Ewy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparando os modelos para inferência e tokenização"
      ],
      "metadata": {
        "id": "i-OUM6vjHzJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparando os modelos"
      ],
      "metadata": {
        "id": "f9NHJtBxQUox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'NousResearch/Llama-2-7b-chat-hf'\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "z9gG1SUbFcnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set quantization configuration to load large model with less GPU memory\n",
        "# this requires the `bitsandbytes` library\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "5qpGTBS7FtCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# begin initializing HF items, you need an access token\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id\n",
        ")"
      ],
      "metadata": {
        "id": "Gf6IW4ZnFxoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e6f2a05604734de1874b861d393542ac",
            "f86a85ce7a9042d6aaca009064444ecd",
            "912a59f189e945b2a5bb8773633b8371",
            "1e0643baa00641438656efaa3adbf268",
            "96a8dffd38d24ecdaec794dfd9a48433",
            "2e08fa3808cf4951a829cc6f38fc5002",
            "25316da561594da8af0c3dbcca4d8b5b",
            "29c92fbe58874d558124a3efa0ac184f",
            "888e93a91be54db1ac8026d01ee2da90",
            "53c2b2896e244b84b070fc45e339c8aa",
            "c5ad50e1877646059619ff3c01a9b146"
          ]
        },
        "id": "n6eoz1y8G45S",
        "outputId": "c1745ed1-ac88-4f87-92a6-17a3700afcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6f2a05604734de1874b861d393542ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# enable evaluation mode to allow model inference\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeZOLZ4SG-aW",
        "outputId": "3c8b4170-1e2c-4c7d-db29-475f15f77055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ISLPvzoHud5",
        "outputId": "f391e031-c217-4d41-9885-e29fa1523612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definindo critérios de parada"
      ],
      "metadata": {
        "id": "oSUyIt2sJqL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_list = ['\\nHuman:', '\\n```\\n']\n",
        "\n",
        "stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n",
        "stop_token_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75gbpkHDJplM",
        "outputId": "231074e8-620f-4fd4-c2c1-5a457298ebf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 29871, 13, 29950, 7889, 29901], [1, 29871, 13, 28956, 13]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
        "stop_token_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBJFtvp5JjOU",
        "outputId": "7b720f6f-041c-43ea-8328-fd47bc9f8330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([    1, 29871,    13, 29950,  7889, 29901], device='cuda:0'),\n",
              " tensor([    1, 29871,    13, 28956,    13], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "# define custom stopping criteria object\n",
        "class StopOnTokens(StoppingCriteria):\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop_ids in stop_token_ids:\n",
        "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
      ],
      "metadata": {
        "id": "PZt_2OdAONjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definindo o pipeline de inferência"
      ],
      "metadata": {
        "id": "Wqhox4Z9Qt9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,  # langchain expects the full text\n",
        "    task='text-generation',\n",
        "    # we pass model parameters here too\n",
        "    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
        "    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
        "    max_new_tokens=4000,  # max number of tokens to generate in the output\n",
        "    repetition_penalty=1.1  # without this output begins repeating\n",
        ")"
      ],
      "metadata": {
        "id": "Y_HzoFwLOW3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = generate_text(\"Compare the personalities of the Bennet sisters from Jane Austen's Pride and Prejudice.\")\n",
        "print(res[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDBCXACoOqCt",
        "outputId": "df08c8b1-2402-419c-fe78-b6400ed3cb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compare the personalities of the Bennet sisters from Jane Austen's Pride and Prejudice. Unterscheidung der Persönlichkeitsmerkmale der Bennet-Schwestern aus Jane Austens \"Pride and Prejudice\".\n",
            "\n",
            "In Jane Austen's novel \"Pride and Prejudice,\" the Bennet sisters are a lively and diverse group of women, each with their own unique personality traits. Here is a comparison of the personalities of the Bennet sisters:\n",
            "\n",
            "1. Elizabeth Bennet - The eldest Bennet sister, Elizabeth is intelligent, witty, and independent. She is also strong-willed and determined, often to the point of being stubborn. Her pride and prejudices often lead her into misunderstandings and conflicts with Mr. Darcy, but she eventually learns to see him in a more favorable light.\n",
            "2. Jane Bennet - The middle Bennet sister, Jane is kind, gentle, and affectionate. She is also very sensitive and emotional, often tearfully expressing her feelings. While she is not as outspoken or assertive as her sister Elizabeth, she is a loyal and supportive friend.\n",
            "3. Mary Bennet - The middle Bennet sister, Mary is bookish, studious, and uninterested in social events. She is often criticized for her lack of beauty, both inside and out, and is seen as dull and unattractive by society. Despite this, she is a kind and well-meaning person who is simply not suited to the frivolous world of the Bennet family.\n",
            "4. Kitty Bennet - The youngest Bennet sister, Kitty is silly, flighty, and easily influenced by those around her. She is often giddy and giggly, and is prone to making foolish decisions. However, she is also friendly and sociable, and has a good heart despite her flaws.\n",
            "5. Lydia Bennet - The most immature and impulsive of the Bennet sisters, Lydia is known for her wild behavior and reckless decisions. She is often irresponsible and thoughtless, and is prone to getting into trouble through her own actions. However, she is also energetic and fun-loving, and has a playful spirit that can be endearing at times.\n",
            "6. Catherine Bennet (Lady Catherine de Bourgh) - The matriarch of the Bennet family, Lady Catherine is a formidable and authoritarian figure. She is haughty, condescending, and dismissive of those she considers beneath her, including the Bennet family. Despite her cold exterior, she is fiercely protective of her status and reputation, and will stop at nothing to maintain her position in society.\n",
            "\n",
            "Overall, the Bennet sisters are a diverse and dynamic group of women, each with their own unique personality traits and flaws. While they may not always get along or see eye to eye, they are all deeply connected and loving towards one another, and ultimately learn to appreciate and value each other's differences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adicionando o pipeline definido na langchain"
      ],
      "metadata": {
        "id": "UKFUgx0YTf8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# checking again that everything is working fine\n",
        "print(llm(prompt=\"Compare the personalities of the Bennet sisters from Jane Austen's Pride and Prejudice.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ6kL3mZOvEG",
        "outputId": "a96f5ab5-ef1c-4181-c504-e05ceed95f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Unterscheidung der Persönlichkeitsmerkmale der Bennet-Schwestern aus Jane Austens \"Pride and Prejudice\".\n",
            "\n",
            "In Jane Austen's novel \"Pride and Prejudice,\" the Bennet sisters are a lively and diverse group of women, each with their own unique personality traits. Here is a comparison of the personalities of the Bennet sisters:\n",
            "\n",
            "1. Elizabeth Bennet - The eldest Bennet sister, Elizabeth is intelligent, witty, and independent. She is also strong-willed and determined, often to the point of being stubborn. Her pride and prejudices often lead her into misunderstandings and conflicts with Mr. Darcy, but she eventually learns to see him in a more favorable light.\n",
            "2. Jane Bennet - The middle Bennet sister, Jane is kind, gentle, and affectionate. She is also very sensitive and emotional, often tearfully expressing her feelings. While she is not as outspoken or assertive as her sister Elizabeth, she is a loyal and supportive friend.\n",
            "3. Mary Bennet - The middle Bennet sister, Mary is bookish, studious, and uninterested in social events. She is often criticized for her lack of beauty, both inside and out, and is seen as dull and unattractive by society. Despite this, she is a kind and well-meaning person who is simply not suited to the frivolous world of the Bennet family.\n",
            "4. Kitty Bennet - The youngest Bennet sister, Kitty is silly, flighty, and easily influenced by those around her. She is often giddy and giggly, and is prone to making foolish decisions. However, she is also friendly and sociable, and has a good heart despite her flaws.\n",
            "5. Lydia Bennet - The most immature and impulsive of the Bennet sisters, Lydia is known for her wild behavior and reckless decisions. She is often irresponsible and thoughtless, and is prone to getting into trouble through her own actions. However, she is also energetic and fun-loving, and has a playful spirit that can be endearing at times.\n",
            "6. Catherine Bennet (Lady Catherine de Bourgh) - The matriarch of the Bennet family, Lady Catherine is a formidable and authoritarian figure. She is haughty, condescending, and dismissive of those she considers beneath her, including the Bennet family. Despite her cold exterior, she is fiercely protective of her status and reputation, and will stop at nothing to maintain her position in society.\n",
            "\n",
            "Overall, the Bennet sisters are a diverse and dynamic group of women, each with their own unique personality traits and flaws. While they may not always get along or see eye to eye, they are all deeply connected and loving towards one another, and ultimately learn to appreciate and value each other's differences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparando os dados e o banco de vetores"
      ],
      "metadata": {
        "id": "rHwkF9HqKNgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "web_links = [\"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"]\n",
        "\n",
        "loader = WebBaseLoader(web_links)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "7V55V9lWJy1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "IR1mVd5gKbY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
        "\n",
        "# storing embeddings in the vector store\n",
        "vectorstore = FAISS.from_documents(all_splits, embeddings)"
      ],
      "metadata": {
        "id": "7hDGOaavK9yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inicializando a chain"
      ],
      "metadata": {
        "id": "w7j-Ike6L4jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)"
      ],
      "metadata": {
        "id": "NkpSKWM4L4K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversando com os seus dados"
      ],
      "metadata": {
        "id": "zGQ74JE9L_ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "query = \"What are some themes in the story?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YMhntBMLgiT",
        "outputId": "b3ce36b7-988b-4291-f2c8-3c0f104730b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Great! Here are some possible themes that might emerge from the text:\n",
            "\n",
            "1. Expectations vs. Reality: The story sets up expectations for the Gardiners' arrival, but the reality is quite different. Elizabeth is surprised to find her uncle alone, and the girls are excited to see their father but can't find him. This theme explores the idea of how our expectations don't always align with reality.\n",
            "2. Family Dynamics: The story highlights the complexities of family dynamics, particularly between the Gardiners and the Bennetts. The girls' excitement to see their father is contrasted with their mother's worry and their uncle's absence. This theme could explore the tensions and relationships within families.\n",
            "3. Social Hierarchy: The mention of Mr. Wickham's miniature on the mantelpiece suggests a social hierarchy. The Gardiners are upper class, while the Bennetts are lower class. This theme could explore the class distinctions in society and how they impact relationships.\n",
            "4. Personal Growth: Elizabeth's reaction to seeing her uncle's picture suggests that she may be growing up and developing her own identity. This theme could explore how characters navigate their personal growth and development throughout the story.\n",
            "5. Miscommunication and Surprise: The story relies heavily on miscommunication and surprise, which could be a theme in itself. Characters are often surprised by events or misunderstand what is happening around them. This theme could explore how communication breakdowns can lead to unexpected consequences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "\n",
        "query = \"Who is the author of pride and prejudice?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5vHXtacMLbe",
        "outputId": "26a5c6a3-9166-4d5e-db80-769ae2d7dd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  The author of Pride and Prejudice is Jane Austen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['source_documents'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVum85Z5MLQf",
        "outputId": "8179b826-71b5-49a8-d0c1-c981951fc3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='The Project Gutenberg eBook of Pride and Prejudice\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere in the United States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\r\\nof the Project Gutenberg License included with this ebook or online\\r\\nat www.gutenberg.org. If you are not located in the United States,\\r\\nyou will have to check the laws of the country where you are located\\r\\nbefore using this eBook.\\r\\n\\r\\nTitle: Pride and Prejudice\\r\\n\\r\\n\\r\\nAuthor: Jane Austen\\r\\n\\r\\nRelease date: June 1, 1998 [eBook #1342]\\r\\n                Most recently updated: April 14, 2023\\r\\n\\r\\nLanguage: English\\r\\n\\r\\nCredits: Chuck Greif and the Online Distributed Proofreading Team at http://www.pgdp.net (This file was produced from images available at The Internet Archive)\\r\\n\\r\\n\\r\\n*** START OF THE PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE ***\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n                            [Illustration:', metadata={'source': 'https://www.gutenberg.org/cache/epub/1342/pg1342.txt'}), Document(page_content='more than one school of critics, that construction is not the highest\\r\\nmerit, the choicest gift, of the novelist. It sets off his other gifts\\r\\nand graces most advantageously to the critical eye; and the want of it\\r\\nwill sometimes mar those graces--appreciably, though not quite\\r\\nconsciously--to eyes by no means ultra-critical. But a very badly-built\\r\\nnovel which excelled in pathetic or humorous character, or which\\r\\ndisplayed consummate command of dialogue--perhaps the rarest of all\\r\\nfaculties--would be an infinitely better thing than a faultless plot\\r\\nacted and told by puppets with pebbles in their mouths. And despite the\\r\\nability which Miss Austen has shown in working out the story, I for one\\r\\nshould put_ Pride and Prejudice _far lower if it did not contain what\\r\\nseem to me the very masterpieces of Miss Austen’s humour and of her\\r\\nfaculty of character-creation--masterpieces who may indeed admit John\\r\\nThorpe, the Eltons, Mrs. Norris, and one or two others to their company,', metadata={'source': 'https://www.gutenberg.org/cache/epub/1342/pg1342.txt'}), Document(page_content='Eltons, cannot but unite the suffrages of everybody. On the other hand,\\r\\nI, for my part, declare for_ Pride and Prejudice _unhesitatingly. It\\r\\nseems to me the most perfect, the most characteristic, the most\\r\\neminently quintessential of its author’s works; and for this contention\\r\\nin such narrow space as is permitted to me, I propose here to show\\r\\ncause._\\r\\n\\r\\n_In the first place, the book (it may be barely necessary to remind the\\r\\nreader) was in its first shape written very early, somewhere about 1796,\\r\\nwhen Miss Austen was barely twenty-one; though it was revised and\\r\\nfinished at Chawton some fifteen years later, and was not published till\\r\\n1813, only four years before her death. I do not know whether, in this\\r\\ncombination of the fresh and vigorous projection of youth, and the\\r\\ncritical revision of middle life, there may be traced the distinct\\r\\nsuperiority in point of construction, which, as it seems to me, it\\r\\npossesses over all the others. The plot, though not elaborate, is almost', metadata={'source': 'https://www.gutenberg.org/cache/epub/1342/pg1342.txt'}), Document(page_content='related as made by himself to Lady Catherine, “May I ask whether these\\r\\npleasing attentions proceed from the impulse of the moment, or are the\\r\\nresult of previous study?” These are the things which give Miss Austen’s\\r\\nreaders the pleasant shocks, the delightful thrills, which are felt by\\r\\nthe readers of Swift, of Fielding, and we may here add, of Thackeray, as\\r\\nthey are felt by the readers of no other English author of fiction\\r\\noutside of these four._\\r\\n\\r\\n_The goodness of the minor characters in_ Pride and Prejudice _has been\\r\\nalready alluded to, and it makes a detailed dwelling on their beauties\\r\\ndifficult in any space, and impossible in this. Mrs. Bennet we have\\r\\nglanced at, and it is not easy to say whether she is more exquisitely\\r\\namusing or more horribly true. Much the same may be said of Kitty and\\r\\nLydia; but it is not every author, even of genius, who would have\\r\\ndifferentiated with such unerring skill the effects of folly and', metadata={'source': 'https://www.gutenberg.org/cache/epub/1342/pg1342.txt'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-N7YaPihMLHD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}